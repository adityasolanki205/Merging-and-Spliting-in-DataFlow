{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import argparse\n",
    "from google.cloud import pubsub_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification_type = [1,2]\n",
    "SCHEMA='Duration_month:INTEGER,Credit_history:STRING,Credit_amount:FLOAT,Saving:STRING,Employment_duration:STRING,Installment_rate:INTEGER,Personal_status:STRING,Debtors:STRING,Residential_Duration:INTEGER,Property:STRING,Age:INTEGER,Installment_plans:STRING,Housing:STRING,Number_of_credits:INTEGER,Job:STRING,Liable_People:INTEGER,Telephone:STRING,Foreign_worker:STRING,Classification:INTEGER,Month:STRING,Days:INTEGER,File_Month:STRING,Version:INTEGER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Split(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        Existing_account,Duration_month,Credit_history,Purpose,Credit_amount,Saving,Employment_duration,Installment_rate,Personal_status,Debtors,Residential_Duration,Property,Age,Installment_plans,Housing,Number_of_credits,Job,Liable_People,Telephone,Foreign_worker,Classification = element.split(' ')\n",
    "        return [{\n",
    "            'Existing_account': str(Existing_account),\n",
    "            'Duration_month': str(Duration_month),\n",
    "            'Credit_history': str(Credit_history),\n",
    "            'Purpose': str(Purpose),\n",
    "            'Credit_amount': str(Credit_amount),\n",
    "            'Saving': str(Saving),\n",
    "            'Employment_duration':str(Employment_duration),\n",
    "            'Installment_rate': str(Installment_rate),\n",
    "            'Personal_status': str(Personal_status),\n",
    "            'Debtors': str(Debtors),\n",
    "            'Residential_Duration': str(Residential_Duration),\n",
    "            'Property': str(Property),\n",
    "            'Age': str(Age),\n",
    "            'Installment_plans':str(Installment_plans),\n",
    "            'Housing': str(Housing),\n",
    "            'Number_of_credits': str(Number_of_credits),\n",
    "            'Job': str(Job),\n",
    "            'Liable_People': str(Liable_People),\n",
    "            'Telephone': str(Telephone),\n",
    "            'Foreign_worker': str(Foreign_worker),\n",
    "            'Classification': str(Classification)\n",
    "        }]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch_Split(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        Existing_account,Duration_month,Credit_history,Purpose,Credit_amount,Saving,Employment_duration,Installment_rate,Personal_status,Debtors,Residential_Duration,Property,Age,Installment_plans,Housing,Number_of_credits,Job,Liable_People,Telephone,Foreign_worker,Classification = element.split(' ')\n",
    "        return [{\n",
    "            'Existing_account': str(Existing_account),\n",
    "            'Duration_month': str(Duration_month),\n",
    "            'Credit_history': str(Credit_history),\n",
    "            'Purpose': str(Purpose),\n",
    "            'Credit_amount': str(Credit_amount),\n",
    "            'Saving': str(Saving),\n",
    "            'Employment_duration':str(Employment_duration),\n",
    "            'Installment_rate': str(Installment_rate),\n",
    "            'Personal_status': str(Personal_status),\n",
    "            'Debtors': str(Debtors),\n",
    "            'Residential_Duration': str(Residential_Duration),\n",
    "            'Property': str(Property),\n",
    "            'Age': str(Age),\n",
    "            'Installment_plans':str(Installment_plans),\n",
    "            'Housing': str(Housing),\n",
    "            'Number_of_credits': str(Number_of_credits),\n",
    "            'Job': str(Job),\n",
    "            'Liable_People': str(Liable_People),\n",
    "            'Telephone': str(Telephone),\n",
    "            'Foreign_worker': str(Foreign_worker),\n",
    "            'Classification': str(Classification)\n",
    "        }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter_Data(data):\n",
    "    #This will remove rows the with Null values in any one of the columns\n",
    "    return data['Purpose'] !=  'NULL' and len(data['Purpose']) <= 3  and  data['Classification'] !=  'NULL' and data['Property'] !=  'NULL' and data['Personal_status'] != 'NULL' and data['Existing_account'] != 'NULL' and data['Credit_amount'] != 'NULL' and data['Installment_plans'] != 'NULL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert_Datatype(data):\n",
    "    #This will convert the datatype of columns from String to integers or Float values\n",
    "    data['Duration_month'] = int(data['Duration_month']) if 'Duration_month' in data else None\n",
    "    data['Credit_amount'] = float(data['Credit_amount']) if 'Credit_amount' in data else None\n",
    "    data['Installment_rate'] = int(data['Installment_rate']) if 'Installment_rate' in data else None\n",
    "    data['Residential_Duration'] = int(data['Residential_Duration']) if 'Residential_Duration' in data else None\n",
    "    data['Age'] = int(data['Age']) if 'Age' in data else None\n",
    "    data['Number_of_credits'] = int(data['Number_of_credits']) if 'Number_of_credits' in data else None\n",
    "    data['Liable_People'] = int(data['Liable_People']) if 'Liable_People' in data else None\n",
    "    data['Classification'] =  int(data['Classification']) if 'Classification' in data else None\n",
    "   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Wrangle(data):\n",
    "    #Here we perform data wrangling where Values in columns are converted to make more sense\n",
    "    Month_Dict = {\n",
    "    'A':'January',\n",
    "    'B':'February',\n",
    "    'C':'March',\n",
    "    'D':'April',\n",
    "    'E':'May',\n",
    "    'F':'June',\n",
    "    'G':'July',\n",
    "    'H':'August',\n",
    "    'I':'September',\n",
    "    'J':'October',\n",
    "    'K':'November',\n",
    "    'L':'December'\n",
    "    }\n",
    "    existing_account = list(data['Existing_account'])\n",
    "    for i in range(len(existing_account)):\n",
    "        month = Month_Dict[existing_account[0]]\n",
    "        days = int(''.join(existing_account[1:]))\n",
    "        data['Month'] = month\n",
    "        data['Days'] = days\n",
    "    purpose = list(data['Purpose'])\n",
    "    for i in range(len(purpose)):\n",
    "        file_month = Month_Dict[purpose[0]]\n",
    "        version = int(''.join(purpose[1:]))\n",
    "        data['File_Month'] = file_month\n",
    "        data['Version'] = version\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Del_Unwanted(data):\n",
    "    #Here we delete redundant columns\n",
    "    del data['Purpose']\n",
    "    del data['Existing_account']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def By_Classification(data , n):\n",
    "    return Classification_type.index(data['Classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(argv=None, save_main_session=True):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--input_file',\n",
    "        dest='input_file',\n",
    "        help='File that will have data of the input'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--input_topic',\n",
    "        dest='input_topic',\n",
    "        help='Topic that will have data of the input'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--project',\n",
    "        dest='project',\n",
    "        help='Project used for this Pipeline'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--output_file',\n",
    "        dest='output_file',\n",
    "        help='Bucket in which Pipeline has to be written'\n",
    "    )\n",
    "    known_args, pipeline_args = parser.parser_known_args(argv)\n",
    "    Options = PipelineOptions(pipeline_args)\n",
    "    with beam.Pipeline(options=Options) as p:\n",
    "        Topic_Input   =  (p  \n",
    "                         | 'Read from Pub Sub' >> beam.io.ReadFromPubSub(topic=known_args.input_topic).with_output_types(bytes)\n",
    "                         )\n",
    "        File_Input  =    (p\n",
    "                         | 'Read from Cloud Storage Bucket' >> beam.io.ReadFromText(known_args.input_file)\n",
    "                         )\n",
    "        Decoded_Online_Input =(Topic_Input \n",
    "                         | 'Decodeing the input Message' >> beam.Map(lambda x: x.decode('utf-8'))\n",
    "                         )\n",
    "        Spliting_Online_Input = (Decoded_Online_Input\n",
    "                         | 'Spliting Streaming Input' >> beam.ParDo(Split())\n",
    "                         )\n",
    "        Spliting_Batch_Input = (File_Input\n",
    "                         | 'Spliting Batch Input' >> beam.ParDo(Split())\n",
    "                         )\n",
    "        Merged_Inputs =  ((Spliting_Online_Input, Spliting_Batch_Input) \n",
    "                         | 'Mergeing Inputs' >> beam.Flatten()\n",
    "                         )\n",
    "        Filtered_Data =  ( Merged_Inputs \n",
    "                         | 'Filtering Data' >> beam.Filter(Filter_Data)\n",
    "                         )\n",
    "        Converted_Data = ( Filtered_Data \n",
    "                         | 'Converting Datatype' >> beam.Map(Convert_Datatype)\n",
    "                         )\n",
    "        Wrangled_data =  ( Converted_Data\n",
    "                         | 'Data Wrangling' >> beam.Map(Data_Wrangle)\n",
    "                         )\n",
    "        Clean_Data  =    ( Wrangled_data\n",
    "                         | 'Deleting Unwanted Columns' >> beam.Map(Del_Unwanted)\n",
    "                         ) \n",
    "        Partition_for_GCS, Partition_for_BQ = ( Clean_Data\n",
    "                         | 'Partitioning Data' >> beam.Partition(By_Classification, 2)\n",
    "                         )\n",
    "        \n",
    "        BQ_Output =      ( Partition_for_BQ \n",
    "                         | 'Inserting Data in BigQuery' >> beam.WriteToBigQuery(\n",
    "                            '{0}:GermanCredit.GermanCreditTable'.format(PROJECT_ID),\n",
    "                             schema=SCHEMA,\n",
    "                             write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND \n",
    "                             )\n",
    "                         ) \n",
    "        GCS_Output =     ( Partition_for_GCS \n",
    "                         | 'Writing a file in GCS' >> beam.WriteToText(known_args.output_file, file_name_suffix = '.json')                  \n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ = '__main__':\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
